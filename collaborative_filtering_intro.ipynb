{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0003cb4-18fb-4ad8-b5d7-24a1626e066c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Collaborative filtering project\n",
    "\n",
    "In this project, the task is to create a paper recommendation system. The system consists of 10,000 scientists and 1,000 papers. Scientists give ratings between 1–5 to the papers that they read. Since not all scientists have read every paper, we only have a limited amount of observations of these ratings. Additionally, each scientist has a wishlist of papers that they would like to read in the future. Your task is to fill in the missing observations using the provided rating and wishlist data, such that we can recommend papers to scientists that we expect them to rate highly.\n",
    "\n",
    "More specifically, there are three data sources:\n",
    " - `train_tbr.csv` containing wishlist data.\n",
    " - `train_ratings.csv` containing observed rating data.\n",
    " - `sample_submission.csv` containing (scientist, paper) pairs that have to be rated for the evaluation of your method.\n",
    "\n",
    "The data is available at `/cluster/courses/cil/collaborative_filtering/data` and an environment has been prepared for you at `/cluster/courses/cil/envs/collaborative_filtering`. You can activate the environment in your shell by running:\n",
    "```bash\n",
    "conda activate /cluster/courses/cil/envs/collaborative_filtering\n",
    "```\n",
    "If you wish to use notebooks on the cluster, you need to set the Environment path to `/cluster/courses/cil/envs/collaborative_filtering/bin` and load the `cuda/12.6` module.\n",
    "\n",
    "**Evaluation**: Your models are evaluated using the root mean-squared error (RMSE) metric. Your grade is determined by a linear interpolation between the easy (grade 4) and hard (grade 6) baselines.\n",
    "\n",
    "**Rules**: You are only allowed to use the data provided in `train_tbr.csv` and `train_ratings.csv` to make your predictions of `sample_submission.csv`. You are not allowed to use external data sources. But, you are allowed to use pre-trained models, as long as they are available publicly. Furthermore, no external API calls are allowed, except for downloading the weights of pre-trained models.\n",
    "\n",
    "**We will verify your code for plagiarism and using solutions from previous years.**\n",
    "\n",
    "[Link to Kaggle competition](https://www.kaggle.com/competitions/ethz-cil-collaborative-filtering-2025)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d799b9af-d742-4cac-a937-06102e652812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Callable\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0063fd35-caac-4ced-b13e-b49cfb58d9a2",
   "metadata": {},
   "source": [
    "Make sure that results are reproducible by using a seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e73627bd-1106-4276-a498-32b44f1b5c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b5b6d6-37ed-40d1-b651-962c611a22c3",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b93bc867-b2d9-4cf7-9bb8-ecb13c663eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \".\"\n",
    "\n",
    "\n",
    "def read_data_df() -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Reads in data and splits it into training and validation sets with a 75/25 split.\"\"\"\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(DATA_DIR, \"train_ratings.csv\"))\n",
    "\n",
    "    # Split sid_pid into sid and pid columns\n",
    "    df[[\"sid\", \"pid\"]] = df[\"sid_pid\"].str.split(\"_\", expand=True)\n",
    "    df = df.drop(\"sid_pid\", axis=1)\n",
    "    df[\"sid\"] = df[\"sid\"].astype(int)\n",
    "    df[\"pid\"] = df[\"pid\"].astype(int)\n",
    "    \n",
    "    # Split into train and validation dataset\n",
    "    train_df, valid_df = train_test_split(df, test_size=0.25)\n",
    "    return train_df, valid_df\n",
    "\n",
    "\n",
    "def read_data_matrix(df: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"Returns matrix view of the training data, where columns are scientists (sid) and\n",
    "    rows are papers (pid).\"\"\"\n",
    "\n",
    "    return df.pivot(index=\"sid\", columns=\"pid\", values=\"rating\").values\n",
    "\n",
    "\n",
    "def read_wishlist_df() -> pd.DataFrame:\n",
    "    \"\"\"Reads in the wishlist data (train_tbr.csv).\"\"\"\n",
    "    \n",
    "    tbr_df = pd.read_csv(os.path.join(DATA_DIR, \"train_tbr.csv\"))\n",
    "    # Ensure sid and pid are integers\n",
    "    tbr_df[\"sid\"] = tbr_df[\"sid\"].astype(int)\n",
    "    tbr_df[\"pid\"] = tbr_df[\"pid\"].astype(int)\n",
    "    return tbr_df\n",
    "\n",
    "\n",
    "def read_wishlist_matrix(df: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"Returns matrix view of the wishlist data.\n",
    "    Rows are scientists (sid), columns are papers (pid).\n",
    "    Values are 1 if the paper is on the wishlist, NaN otherwise.\"\"\"\n",
    "    \n",
    "    # Add a temporary column with value 1 for pivoting\n",
    "    df_copy = df.copy()\n",
    "    df_copy['wishlisted'] = 1\n",
    "\n",
    "\n",
    "    all_sids = pd.Index(range(10000))\n",
    "    wishlist_matrix = df_copy.pivot(index=\"sid\", columns=\"pid\", values=\"wishlisted\")\n",
    "    wishlist_matrix = wishlist_matrix.reindex(all_sids)\n",
    "\n",
    "    return wishlist_matrix.values\n",
    "\n",
    "def evaluate(valid_df: pd.DataFrame, pred_fn: Callable[[np.ndarray, np.ndarray], np.ndarray]) -> float:\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        valid_df: Validation data, returned from read_data_df for example.\n",
    "        pred_fn: Function that takes in arrays of sid and pid and outputs their rating predictions.\n",
    "\n",
    "    Outputs: Validation RMSE\n",
    "    \"\"\"\n",
    "    \n",
    "    preds = pred_fn(valid_df[\"sid\"].values, valid_df[\"pid\"].values)\n",
    "    return root_mean_squared_error(valid_df[\"rating\"].values, preds)\n",
    "\n",
    "\n",
    "def make_submission(pred_fn: Callable[[np.ndarray, np.ndarray], np.ndarray], filename: os.PathLike):\n",
    "    \"\"\"Makes a submission CSV file that can be submitted to kaggle.\n",
    "\n",
    "    Inputs:\n",
    "        pred_fn: Function that takes in arrays of sid and pid and outputs a score.\n",
    "        filename: File to save the submission to.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(DATA_DIR, \"sample_submission.csv\"))\n",
    "\n",
    "    # Get sids and pids\n",
    "    sid_pid = df[\"sid_pid\"].str.split(\"_\", expand=True)\n",
    "    sids = sid_pid[0]\n",
    "    pids = sid_pid[1]\n",
    "    sids = sids.astype(int).values\n",
    "    pids = pids.astype(int).values\n",
    "    \n",
    "    df[\"rating\"] = pred_fn(sids, pids)\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deb53ec-a5aa-408c-b6a5-118ffe14c035",
   "metadata": {},
   "source": [
    "## Singular value decomposition\n",
    "\n",
    "For the first method in this introduction, we will make use of the singular value decomposition (SVD) to construct the optimal rank-$k$ approximation (when measuring the Frobenius norm as error), according to the Eckart-Young theorem. Since the matrix needs to be fully observed in order to make use of SVD, we need to impute the missing values. In this case, we impute values with $3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3495d53a-ec1e-4692-a19b-6d8aa5fcf88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_values(mat: np.ndarray) -> np.ndarray:\n",
    "    return np.nan_to_num(mat, nan=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a08ecda7-3e44-4d99-894d-6927a12fe54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings_df, valid_ratings_df = read_data_df()\n",
    "train_wishlist_df = read_wishlist_df()\n",
    "\n",
    "train_mat = read_data_matrix(train_df)\n",
    "train_wishlist_mat = read_wishlist_matrix(train_wishlist_df)\n",
    "\n",
    "train_mat += 4 * train_wishlist_mat\n",
    "train_mat = impute_values(train_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0f457d-7dd2-448e-8282-792904b67298",
   "metadata": {},
   "source": [
    "### Singular value spectrum\n",
    "\n",
    "In order to assess which rank $k$ to use for the reconstruction matrix, we look at the spectrum of singular values and look for the \"elbow\". In this case, we will use $k=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8d0f8500-fb85-4bf4-a609-eb8a366587d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "singular_values = np.linalg.svd(train_mat, compute_uv=False, hermitian=False)\n",
    "plt.plot(singular_values)\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Singular value spectrum\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1a1d01ab-b4bd-43b4-8e3a-d60e94ac2c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_rank_k_approximation(m: np.ndarray, k: int):\n",
    "    \"\"\"Returns the optimal rank-k reconstruction matrix, using SVD.\"\"\"\n",
    "    \n",
    "    assert 0 < k <= np.min(m.shape), f\"The rank must be in [0, min(m, n)]\"\n",
    "    \n",
    "    U, S, Vh = np.linalg.svd(m, full_matrices=False)\n",
    "    \n",
    "    U_k = U[:, :k]\n",
    "    S_k = S[:k]\n",
    "    Vh_k = Vh[:k]\n",
    "    \n",
    "    return np.dot(U_k * S_k, Vh_k)\n",
    "\n",
    "\n",
    "def matrix_pred_fn(train_recon: np.ndarray, sids: np.ndarray, pids: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        train_recon: (M, N) matrix with predicted values for every (sid, pid) pair.\n",
    "        sids: (D,) vector with integer scientist IDs.\n",
    "        pids: (D,) vector with integer paper IDs.\n",
    "        \n",
    "    Outputs: (D,) vector with predictions.\n",
    "    \"\"\"\n",
    "    \n",
    "    return train_recon[sids, pids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfad6c5-2a84-4587-a6da-1232cb8fd9fe",
   "metadata": {},
   "source": [
    "We first obtain the optimal rank-$k$ approximation of the training matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "79b10471-3beb-4809-9bb5-191005b8bcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_recon = opt_rank_k_approximation(train_mat, k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df305d5-6b2a-484a-ab63-dd8911870b6c",
   "metadata": {},
   "source": [
    "Then, the values of this matrix reconstruction are the predictions for all (sid, pid)-pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1d3560ac-e1df-46c5-8da3-335786b49b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 1.301\n"
     ]
    }
   ],
   "source": [
    "pred_fn = lambda sids, pids: matrix_pred_fn(train_recon, sids, pids)\n",
    "\n",
    "# Evaluate on validation data\n",
    "val_score = evaluate(valid_df, pred_fn)\n",
    "print(f\"Validation RMSE: {val_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0c152631-47f5-4b8a-a1a6-90b856d922c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(pred_fn, \"svd_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcc1599-f85a-4684-a608-1c7b98ee1c95",
   "metadata": {},
   "source": [
    "## Learned embeddings\n",
    "\n",
    "Next, we will take a machine learning view of the problem. To each scientist and paper, we assign a $d$-dimensional embedding and we predict the rating that the scientist gives the paper to be their dot product. More formally, let $\\vec{s}_i$ be a scientist embedding and $\\vec{p}_j$ be a paper embedding. Then, we make the following rating prediction for this pair: $$\\tilde{r}_{ij} = \\langle \\vec{s}_i, \\vec{p}_j \\rangle.$$ We view these embeddings as our learnable parameters and train them as we would any other model using the squared error loss function: $$\\ell(\\theta) = \\frac{1}{2} |\\langle \\vec{s}_i, \\vec{p}_j \\rangle - r_{ij}|^2,$$ where $\\theta = \\{ \\vec{s}_i \\}_{i=1}^n \\cup \\{ \\vec{p}_j \\}_{j=1}^m$. The following is an implementation of this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "67fcd1d8-93dc-45e7-9706-554b9d1edc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "30c1d236-0b95-4a68-9447-4ad7042d5a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDotProductModel(nn.Module):\n",
    "    def __init__(self, num_scientists: int, num_papers: int, dim: int):\n",
    "        super().__init__()\n",
    "\n",
    "        # Assign to each scientist and paper an embedding\n",
    "        self.scientist_emb = nn.Embedding(num_scientists, dim)\n",
    "        self.paper_emb = nn.Embedding(num_papers, dim)\n",
    "        \n",
    "    def forward(self, sid: torch.Tensor, pid: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            sid: [B,], int\n",
    "            pid: [B,], int\n",
    "        \n",
    "        Outputs: [B,], float\n",
    "        \"\"\"\n",
    "\n",
    "        # Per-pair dot product\n",
    "        return torch.sum(self.scientist_emb(sid) * self.paper_emb(pid), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135658a9-8890-4e1e-a5ae-a500e7fc0da2",
   "metadata": {},
   "source": [
    "Set $d=32$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "5637bee3-2b0c-425e-b6b1-e13547d5ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model (10k scientists, 1k papers, 32-dimensional embeddings) and optimizer\n",
    "model = EmbeddingDotProductModel(10_000, 1_000, 64).to(device)\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "2e866a9d-d5c6-40f1-b27f-d934eb6a5406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(\n",
    "    df: pd.DataFrame,\n",
    "    wishlist_df: pd.DataFrame = None\n",
    ") -> torch.utils.data.Dataset:\n",
    "    \"\"\"\n",
    "    Returns a dataset of (sid, pid, rating, wishlist_flag) for every\n",
    "    (sid,pid) in ratings OR wishlist.  Missing ratings or wishlist\n",
    "    entries are filled with 0.0.\n",
    "    \"\"\"\n",
    "    # If no wishlist provided, just add an empty wishlist column\n",
    "    if wishlist_df is None:\n",
    "        merged = df.copy()\n",
    "        merged['wishlist'] = 0.0\n",
    "\n",
    "    else:\n",
    "        # 1) Prepare the wishlist with a flag column:\n",
    "        w = wishlist_df[['sid', 'pid']].copy()\n",
    "        w['wishlist'] = 1.0\n",
    "\n",
    "        # 2) Outer‐merge ratings and wishlist flags on (sid, pid):\n",
    "        merged = pd.merge(\n",
    "            df[['sid', 'pid', 'rating']],\n",
    "            w,\n",
    "            on=['sid', 'pid'],\n",
    "            how='outer'       # <-- full join\n",
    "        )\n",
    "\n",
    "        # 3) Fill missing values:\n",
    "        merged['rating'] = merged['rating'].fillna(0.0)\n",
    "        merged['wishlist'] = merged['wishlist'].fillna(0.0)\n",
    "\n",
    "    # 4) Convert to tensors\n",
    "    sids      = torch.from_numpy(merged['sid'].to_numpy()).long()\n",
    "    pids      = torch.from_numpy(merged['pid'].to_numpy()).long()\n",
    "    ratings   = torch.from_numpy(merged['rating'].to_numpy()).float()\n",
    "    wishlists = torch.from_numpy(merged['wishlist'].to_numpy()).float()\n",
    "\n",
    "    return torch.utils.data.TensorDataset(sids, pids, ratings, wishlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "e05764b4-5103-40fa-8910-3d84ea28a6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_dataset(train_ratings_df, train_wishlist_df)\n",
    "valid_dataset = get_dataset(valid_ratings_df)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "bc4bf04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaCombinedLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    L = α * MSE_on_ratings\n",
    "        + (1-α) * Implicit_loss_on_wishlist\n",
    "\n",
    "    where implicit_loss_on_wishlist = mean_{w=1}[ c * (1 - pred)^2 ].\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        alpha: float = 0.5,\n",
    "        alpha_wish: float = 1.0\n",
    "    ):\n",
    "        \"\"\"\n",
    "        alpha       : weight on the rating‐MSE term\n",
    "        alpha_wish  : confidence multiplier for wishlist entries\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.alpha_wish = alpha_wish\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        preds: torch.Tensor,\n",
    "        ratings: torch.Tensor,\n",
    "        wishlists: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        # 1) MSE on observed ratings\n",
    "        mask_r = ratings > 0\n",
    "        if mask_r.any():\n",
    "            mse = F.mse_loss(preds[mask_r], ratings[mask_r])\n",
    "        else:\n",
    "            mse = torch.tensor(0.0, device=preds.device)\n",
    "\n",
    "        # 2) Implicit paper loss on wishlist items only\n",
    "        mask_w = wishlists > 0\n",
    "        if mask_w.any():\n",
    "            p = torch.ones_like(preds[mask_w])  # p_ui=1\n",
    "            imp = (self.alpha_wish * (p - preds[mask_w]).pow(2)).mean()\n",
    "        else:\n",
    "            imp = torch.tensor(0.0, device=preds.device)\n",
    "\n",
    "        return self.alpha * mse + (1.0 - self.alpha) * imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "cf5e7f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = AlphaCombinedLoss(alpha=0.8, alpha_wish=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8240462-5fc0-4c51-8e84-1082da8bf295",
   "metadata": {},
   "source": [
    "Training loop, which we run for 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085034ab-cb5a-444a-bcf4-a505cfd17e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/25] Train loss=54.750, Valid RMSE=2.598\n",
      "[Epoch 2/25] Train loss=16.358, Valid RMSE=2.047\n",
      "[Epoch 3/25] Train loss=3.759, Valid RMSE=1.550\n",
      "[Epoch 4/25] Train loss=2.584, Valid RMSE=1.462\n",
      "[Epoch 5/25] Train loss=2.344, Valid RMSE=1.435\n",
      "[Epoch 6/25] Train loss=2.173, Valid RMSE=1.417\n",
      "[Epoch 7/25] Train loss=2.029, Valid RMSE=1.418\n",
      "[Epoch 8/25] Train loss=1.908, Valid RMSE=1.420\n",
      "[Epoch 9/25] Train loss=1.803, Valid RMSE=1.425\n",
      "[Epoch 10/25] Train loss=1.708, Valid RMSE=1.422\n",
      "[Epoch 11/25] Train loss=1.626, Valid RMSE=1.428\n",
      "[Epoch 12/25] Train loss=1.550, Valid RMSE=1.433\n",
      "[Epoch 13/25] Train loss=1.483, Valid RMSE=1.437\n",
      "[Epoch 14/25] Train loss=1.424, Valid RMSE=1.444\n",
      "[Epoch 15/25] Train loss=1.369, Valid RMSE=1.443\n",
      "[Epoch 16/25] Train loss=1.321, Valid RMSE=1.448\n",
      "[Epoch 17/25] Train loss=1.279, Valid RMSE=1.453\n",
      "[Epoch 18/25] Train loss=1.241, Valid RMSE=1.457\n",
      "[Epoch 19/25] Train loss=1.205, Valid RMSE=1.461\n",
      "[Epoch 20/25] Train loss=1.174, Valid RMSE=1.467\n",
      "[Epoch 21/25] Train loss=1.147, Valid RMSE=1.468\n",
      "[Epoch 22/25] Train loss=1.121, Valid RMSE=1.471\n",
      "[Epoch 23/25] Train loss=1.098, Valid RMSE=1.476\n",
      "[Epoch 24/25] Train loss=1.079, Valid RMSE=1.478\n",
      "[Epoch 25/25] Train loss=1.059, Valid RMSE=1.479\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "899f051b-6854-4fc4-a380-2f6951768ee4",
   "metadata": {},
   "source": [
    "As we can see, this method already provides an improvement on the validation dataset over the naive SVD method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b73bec67-2ee0-4683-beb1-a102dac072d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 2.984\n"
     ]
    }
   ],
   "source": [
    "pred_fn = lambda sids, pids: model(torch.from_numpy(sids).to(device), torch.from_numpy(pids).to(device)).clamp(1, 5).cpu().numpy()\n",
    "\n",
    "# Evaluate on validation data\n",
    "with torch.no_grad():\n",
    "    val_score = evaluate(valid_df, pred_fn)\n",
    "\n",
    "print(f\"Validation RMSE: {val_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f42b995-2e08-4cfc-90aa-1b59a7e9fd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    make_submission(pred_fn, \"learned_embedding_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aeae800-f6d7-4182-9b7e-aa080e92d87e",
   "metadata": {},
   "source": [
    "## Outlook\n",
    "\n",
    "To further improve the score, students can make use of the information in `train_tbr.csv`, which contains the papers that scientists want to read. Furthermore, students can look into more modern collaborative filtering methods and techniques.\n",
    "\n",
    "Have fun :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fdd37c-3c98-497e-881b-29ce59f88d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMF(nn.Module):\n",
    "    \"\"\"\n",
    "    Generalized Matrix Factorization branch of NCF for research-paper recommendations.\n",
    "    Computes element-wise product of researcher and paper embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_researchers: int, num_papers: int, emb_dim: int):\n",
    "        super(GMF, self).__init__()\n",
    "        self.researcher_emb = nn.Embedding(num_researchers, emb_dim)\n",
    "        self.paper_emb      = nn.Embedding(num_papers, emb_dim)\n",
    "\n",
    "    def forward(self, researcher_indices: torch.LongTensor, paper_indices: torch.LongTensor) -> torch.Tensor:\n",
    "        # Lookup embeddings\n",
    "        r = self.researcher_emb(researcher_indices)  # (batch, emb_dim)\n",
    "        p = self.paper_emb(paper_indices)            # (batch, emb_dim)\n",
    "        return r * p                                 # (batch, emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "a785375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Layer Perceptron branch of NCF for research-paper recommendations.\n",
    "    Concatenates researcher and paper embeddings, then passes through dense layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_researchers: int, num_papers: int, emb_dim: int, mlp_layers: list[int]):\n",
    "        super(MLP, self).__init__()\n",
    "        self.researcher_emb = nn.Embedding(num_researchers, emb_dim)\n",
    "        self.paper_emb      = nn.Embedding(num_papers, emb_dim)\n",
    "\n",
    "        mlp_modules = []\n",
    "        input_size = emb_dim * 2\n",
    "        for hidden_size in mlp_layers:\n",
    "            # We need to concat the researcher and paper embeddings, so the input size is doubled\n",
    "            mlp_modules.append(nn.Linear(input_size, hidden_size))\n",
    "            mlp_modules.append(nn.ReLU())\n",
    "            input_size = hidden_size\n",
    "        self.mlp = nn.Sequential(*mlp_modules)\n",
    "\n",
    "    def forward(self, researcher_indices: torch.LongTensor, paper_indices: torch.LongTensor) -> torch.Tensor:\n",
    "        r = self.researcher_emb(researcher_indices)  # (batch, emb_dim)\n",
    "        p = self.paper_emb(paper_indices)            # (batch, emb_dim)\n",
    "        x = torch.cat([r, p], dim=1)                 # (batch, emb_dim*2)\n",
    "        out = self.mlp(x)                            # (batch, mlp_layers[-1]) \n",
    "        return out                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782ae6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuMF(nn.Module):\n",
    "    \"\"\"\n",
    "    NeuMF: Fusion of GMF and MLP for research-paper recommendation.\n",
    "    Outputs a predicted relevance score (e.g., probability of interest).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_researchers: int,\n",
    "        num_papers: int,\n",
    "        emb_dim: int,\n",
    "        mlp_layers: list[int],\n",
    "    ):\n",
    "        super(NeuMF, self).__init__()\n",
    "        \n",
    "        # GMF branch\n",
    "        self.gmf = GMF(num_researchers, num_papers, emb_dim)\n",
    "        # MLP branch\n",
    "        self.mlp = MLP(num_researchers, num_papers, emb_dim, mlp_layers)\n",
    "\n",
    "        # Final prediction layer\n",
    "        final_size = emb_dim + mlp_layers[-1]\n",
    "        self.predict = nn.Linear(final_size, 1)\n",
    "        self.alpha = 0.7\n",
    "\n",
    "    def forward(self, researcher_indices: torch.LongTensor, paper_indices: torch.LongTensor) -> torch.Tensor:\n",
    "        gmf_out = self.gmf(researcher_indices, paper_indices)  # GMF output: (batch, emb_dim)\n",
    "        mlp_out = self.mlp(researcher_indices, paper_indices)  # MLP output: (batch, mlp_layers[-1])\n",
    "        \n",
    "        # Scale by alpha\n",
    "        h_gmf_scaled = gmf_out * self.alpha\n",
    "        h_mlp_scaled = mlp_out * (1.0 - self.alpha)\n",
    "\n",
    "        # Concatenate and normalize\n",
    "        x = torch.cat([h_gmf_scaled, h_mlp_scaled], dim=1)\n",
    "        out = self.predict(x).squeeze(1)\n",
    "        \n",
    "        return torch.sigmoid(out) * 4.0 + 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023911ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model (10k scientists, 1k papers, 32-dimensional embeddings) and optimizer\n",
    "model = NeuMF(10_000, 1_000, 32, [64, 128, 64]).to(device)\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=4e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "d3654f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(\n",
    "    df: pd.DataFrame\n",
    ") -> torch.utils.data.Dataset:\n",
    "    \"\"\"\n",
    "    Returns a dataset of triplets (researcher_id, paper_id, rating).\n",
    "    \"\"\"\n",
    "    sids    = torch.from_numpy(df['sid'].to_numpy()).long()\n",
    "    pids    = torch.from_numpy(df['pid'].to_numpy()).long()\n",
    "    ratings = torch.from_numpy(df['rating'].to_numpy()).float()\n",
    "\n",
    "    return torch.utils.data.TensorDataset(sids, pids, ratings)\n",
    "\n",
    "# Example usage:\n",
    "train_dataset = get_dataset(train_ratings_df)\n",
    "valid_dataset = get_dataset(valid_ratings_df)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "9c102af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/25] Train loss=0.852, Valid RMSE=0.902\n",
      "[Epoch 2/25] Train loss=0.796, Valid RMSE=0.899\n",
      "[Epoch 3/25] Train loss=0.778, Valid RMSE=0.892\n",
      "[Epoch 4/25] Train loss=0.754, Valid RMSE=0.885\n",
      "[Epoch 5/25] Train loss=0.731, Valid RMSE=0.885\n",
      "[Epoch 6/25] Train loss=0.701, Valid RMSE=0.886\n",
      "[Epoch 7/25] Train loss=0.670, Valid RMSE=0.885\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[490]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m optim.zero_grad()\n\u001b[32m     20\u001b[39m loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Keep track of running loss\u001b[39;00m\n\u001b[32m     24\u001b[39m total_data += \u001b[38;5;28mlen\u001b[39m(sid)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/env/lib/python3.11/site-packages/torch/optim/optimizer.py:493\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    488\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    490\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    491\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/env/lib/python3.11/site-packages/torch/optim/optimizer.py:91\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     90\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     93\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/env/lib/python3.11/site-packages/torch/optim/adamw.py:243\u001b[39m, in \u001b[36mAdamW.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    230\u001b[39m     beta1, beta2 = cast(Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    232\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    233\u001b[39m         group,\n\u001b[32m    234\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    240\u001b[39m         state_steps,\n\u001b[32m    241\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/env/lib/python3.11/site-packages/torch/optim/optimizer.py:154\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/env/lib/python3.11/site-packages/torch/optim/adamw.py:875\u001b[39m, in \u001b[36madamw\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    872\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    873\u001b[39m     func = _single_tensor_adamw\n\u001b[32m--> \u001b[39m\u001b[32m875\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/env/lib/python3.11/site-packages/torch/optim/adamw.py:405\u001b[39m, in \u001b[36m_single_tensor_adamw\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[39m\n\u001b[32m    402\u001b[39m step_t += \u001b[32m1\u001b[39m\n\u001b[32m    404\u001b[39m \u001b[38;5;66;03m# Perform stepweight decay\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m \u001b[43mparam\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    407\u001b[39m device = param.device\n\u001b[32m    409\u001b[39m device = param.device\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 25\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Train model for an epoch\n",
    "    total_loss = 0.0\n",
    "    total_data = 0\n",
    "    model.train()\n",
    "    for sid, pid, ratings in train_loader:\n",
    "        # Move data to GPU\n",
    "        sid = sid.to(device)\n",
    "        pid = pid.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "        wishlists = wishlists.to(device)\n",
    "\n",
    "        # Make prediction and compute loss\n",
    "        pred = model(sid, pid)\n",
    "        loss = F.mse_loss(pred, ratings)\n",
    "\n",
    "        # Compute gradients w.r.t. loss and take a step in that direction\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        # Keep track of running loss\n",
    "        total_data += len(sid)\n",
    "        total_loss += len(sid) * loss.item()\n",
    "\n",
    "    # Evaluate model on validation data\n",
    "    total_val_mse = 0.0\n",
    "    total_val_data = 0\n",
    "    model.eval()\n",
    "    for sid, pid, ratings in valid_loader:\n",
    "        sid = sid.to(device)\n",
    "        pid = pid.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "\n",
    "        # Clamp predictions in [1,5], since all ground-truth ratings are\n",
    "        pred = model(sid, pid).clamp(1, 5)\n",
    "        mse = F.mse_loss(pred, ratings)\n",
    "\n",
    "        # Keep track of running metrics\n",
    "        total_val_data += len(sid)\n",
    "        total_val_mse += len(sid) * mse.item()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}/{NUM_EPOCHS}] Train loss={total_loss / total_data:.3f}, Valid RMSE={(total_val_mse / total_val_data) ** 0.5:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fada4f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d73ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
